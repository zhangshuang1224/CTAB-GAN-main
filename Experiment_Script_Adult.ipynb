{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This jupyter-notebook contains the evaluation of synthetic data generated using CTAB-GAN for the Adult dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the model\n",
    "from model.ctabgan import CTABGAN\n",
    "# Importing the evaluation metrics \n",
    "from model.eval.evaluation import get_utility_metrics,stat_sim,privacy_metrics\n",
    "# Importing standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the replication number \n",
    "num_exp = 1 \n",
    "# Specifying the name of the dataset used \n",
    "dataset = \"Adult\" \n",
    "# Specifying the path of the dataset used \n",
    "real_path = \"Real_Datasets/Adult.csv\" \n",
    "# Specifying the root directory for storing generated data\n",
    "fake_file_root = \"Fake_Datasets\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 positional arguments (and 5 keyword-only arguments) were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Fitting the synthesizer to the training dataset and generating synthetic data\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_exp):\n\u001B[1;32m---> 16\u001B[0m     \u001B[43msynthesizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     syn \u001B[38;5;241m=\u001B[39m synthesizer\u001B[38;5;241m.\u001B[39mgenerate_samples()\n\u001B[0;32m     18\u001B[0m     syn\u001B[38;5;241m.\u001B[39mto_csv(fake_file_root\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mdataset\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39m dataset\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_fake_\u001B[39m\u001B[38;5;132;01m{exp}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(exp\u001B[38;5;241m=\u001B[39mi), index\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\PyCharm\\PycharmProject\\CTAB-GAN-main\\model\\ctabgan.py:59\u001B[0m, in \u001B[0;36mCTABGAN.fit\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     57\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_prep \u001B[38;5;241m=\u001B[39m DataPrep(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw_df,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategorical_columns,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_columns,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmixed_columns,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minteger_columns,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproblem_type,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_ratio)\n\u001B[1;32m---> 59\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msynthesizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_prep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategorical\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_prep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumn_types\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcategorical\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m\u001B[49m\u001B[43mmixed\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_prep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumn_types\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmixed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproblem_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFinished training in\u001B[39m\u001B[38;5;124m'\u001B[39m,end_time\u001B[38;5;241m-\u001B[39mstart_time,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m seconds.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\PyCharm\\PycharmProject\\CTAB-GAN-main\\model\\synthesizer\\ctabgan_synthesizer.py:598\u001B[0m, in \u001B[0;36mCTABGANSynthesizer.fit\u001B[1;34m(self, train_data, categorical, mixed, type)\u001B[0m\n\u001B[0;32m    595\u001B[0m \u001B[38;5;66;03m# transforming pre-processed training data according to different data types \u001B[39;00m\n\u001B[0;32m    596\u001B[0m \u001B[38;5;66;03m# i.e., mode specific normalisation for numeric and mixed columns and one-hot-encoding for categorical columns\u001B[39;00m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer \u001B[38;5;241m=\u001B[39m DataTransformer(train_data\u001B[38;5;241m=\u001B[39mtrain_data, categorical_list\u001B[38;5;241m=\u001B[39mcategorical, mixed_dict\u001B[38;5;241m=\u001B[39mmixed)\n\u001B[1;32m--> 598\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \n\u001B[0;32m    599\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer\u001B[38;5;241m.\u001B[39mtransform(train_data\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m    600\u001B[0m \u001B[38;5;66;03m# storing column size of the transformed training data\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PyCharm\\PycharmProject\\CTAB-GAN-main\\model\\synthesizer\\transformer.py:117\u001B[0m, in \u001B[0;36mDataTransformer.fit\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_dim \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39msum(comp)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m info[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmixed\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    115\u001B[0m     \n\u001B[0;32m    116\u001B[0m     \u001B[38;5;66;03m# in case of mixed columns, two bgm models are used\u001B[39;00m\n\u001B[1;32m--> 117\u001B[0m     gm1 \u001B[38;5;241m=\u001B[39m \u001B[43mBayesianGaussianMixture\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_concentration_prior_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdirichlet_process\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_concentration_prior\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m     gm2 \u001B[38;5;241m=\u001B[39m BayesianGaussianMixture(\n\u001B[0;32m    123\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_clusters,\n\u001B[0;32m    124\u001B[0m         weight_concentration_prior_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdirichlet_process\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    125\u001B[0m         weight_concentration_prior\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[0;32m    126\u001B[0m         n_init\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;66;03m# first bgm model is fit to the entire data only for the purposes of obtaining a normalized value of any particular categorical mode\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() takes 1 positional argument but 2 positional arguments (and 5 keyword-only arguments) were given"
     ]
    }
   ],
   "source": [
    "# Initializing the synthesizer object and specifying input parameters\n",
    "# Notice: If you have continuous variable, you do not need to explicitly assign it. It will be treated like \n",
    "# that by default\n",
    "synthesizer =  CTABGAN(raw_csv_path = real_path,\n",
    "                 test_ratio = 0.20,  \n",
    "                 categorical_columns = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                                        'relationship', 'race', 'gender', 'native-country', 'income'], \n",
    "                 log_columns = [],\n",
    "                 mixed_columns= {'capital-loss':[0.0],'capital-gain':[0.0]}, \n",
    "                 integer_columns = ['age', 'fnlwgt','capital-gain', 'capital-loss','hours-per-week'],\n",
    "                 problem_type= {\"Classification\": 'income'},\n",
    "                 epochs = 150) \n",
    "\n",
    "# Fitting the synthesizer to the training dataset and generating synthetic data\n",
    "for i in range(num_exp):\n",
    "    synthesizer.fit()\n",
    "    syn = synthesizer.generate_samples()\n",
    "    syn.to_csv(fake_file_root+\"/\"+dataset+\"/\"+ dataset+\"_fake_{exp}.csv\".format(exp=i), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the paths to all corresponding generated datasets for evaluation \n",
    "fake_paths = glob.glob(fake_file_root+\"/\"+dataset+\"/\"+\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Utility Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>1.064592</td>\n",
       "      <td>0.009517</td>\n",
       "      <td>0.061383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>6.285188</td>\n",
       "      <td>0.063739</td>\n",
       "      <td>0.071529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>2.589825</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>0.040049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>2.763845</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.126618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>2.896919</td>\n",
       "      <td>0.049234</td>\n",
       "      <td>0.124052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Acc       AUC  F1_Score\n",
       "lr   1.064592  0.009517  0.061383\n",
       "dt   6.285188  0.063739  0.071529\n",
       "rf   2.589825  0.027153  0.040049\n",
       "mlp  2.763845  0.013811  0.126618\n",
       "svm  2.896919  0.049234  0.124052"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying the list of classifiers to conduct ML utility evaluation\n",
    "classifiers_list = [\"lr\",\"dt\",\"rf\",\"mlp\",\"svm\"]\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "result_mat = get_utility_metrics(real_path,fake_paths,\"MinMax\",classifiers_list, test_ratio = 0.20)\n",
    "result_df  = pd.DataFrame(result_mat,columns=[\"Acc\",\"AUC\",\"F1_Score\"])\n",
    "result_df.index = classifiers_list\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Similarity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average WD (Continuous Columns</th>\n",
       "      <th>Average JSD (Categorical Columns)</th>\n",
       "      <th>Correlation Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.761534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average WD (Continuous Columns  Average JSD (Categorical Columns)  \\\n",
       "0                        0.009362                             0.1204   \n",
       "\n",
       "   Correlation Distance  \n",
       "0              0.761534  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying the categorical columns of the dataset used\n",
    "adult_categorical = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "\n",
    "# Storing and presenting the results as a dataframe\n",
    "stat_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    stat_res = stat_sim(real_path,fake_path,adult_categorical)\n",
    "    stat_res_avg.append(stat_res)\n",
    "\n",
    "stat_columns = [\"Average WD (Continuous Columns\",\"Average JSD (Categorical Columns)\",\"Correlation Distance\"]\n",
    "stat_results = pd.DataFrame(np.array(stat_res_avg).mean(axis=0).reshape(1,3),columns=stat_columns)\n",
    "stat_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbour Privacy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DCR between Real and Fake (5th perc)</th>\n",
       "      <th>DCR within Real(5th perc)</th>\n",
       "      <th>DCR within Fake (5th perc)</th>\n",
       "      <th>NNDR between Real and Fake (5th perc)</th>\n",
       "      <th>NNDR within Real (5th perc)</th>\n",
       "      <th>NNDR within Fake (5th perc)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.485676</td>\n",
       "      <td>0.216545</td>\n",
       "      <td>0.22867</td>\n",
       "      <td>0.632722</td>\n",
       "      <td>0.442052</td>\n",
       "      <td>0.431408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DCR between Real and Fake (5th perc)  DCR within Real(5th perc)  \\\n",
       "0                              0.485676                   0.216545   \n",
       "\n",
       "   DCR within Fake (5th perc)  NNDR between Real and Fake (5th perc)  \\\n",
       "0                     0.22867                               0.632722   \n",
       "\n",
       "   NNDR within Real (5th perc)  NNDR within Fake (5th perc)  \n",
       "0                     0.442052                     0.431408  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing and presenting the results as a dataframe\n",
    "priv_res_avg = []\n",
    "for fake_path in fake_paths:\n",
    "    priv_res = privacy_metrics(real_path,fake_path)\n",
    "    priv_res_avg.append(priv_res)\n",
    "    \n",
    "privacy_columns = [\"DCR between Real and Fake (5th perc)\",\"DCR within Real(5th perc)\",\"DCR within Fake (5th perc)\",\"NNDR between Real and Fake (5th perc)\",\"NNDR within Real (5th perc)\",\"NNDR within Fake (5th perc)\"]\n",
    "privacy_results = pd.DataFrame(np.array(priv_res_avg).mean(axis=0).reshape(1,6),columns=privacy_columns)\n",
    "privacy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing generated data for future use if needed\n",
    "syn.to_csv(fake_file_root+\"/\"+dataset+\"/\"+ dataset+\"_fake_{exp}.csv\".format(exp=i), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5bbd4e8a0020626d1955d6e7d647b883363040a056d10513dec12a340be08610"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}